{"title":"SVD Based Image Processing Applications","markdown":{"yaml":{"title":"SVD Based Image Processing Applications","format":{"ieee-html":"default"},"author":[{"id":"dfolio","name":"Siju K S","affiliations":[{"name":"Amrita Vishwa Vidyapeetham","department":"School of Artificial Intelligence","city":"Coimbatore","country":"India","postal-code":18800},{"name":"Unknown affiliation"}],"orcid":"0009-0004-1983-5574","email":"siju.swamy@saintgits.org","url":"https://dfolio.fr/","membership":"Member, IEEE","attributes":{"corresponding":true},"photo":"david-folio.png","bio":"Use `IEEEbiography`  with figure as  option and\nthe author name as the argument followed by the biography text.\n"},{"name":"Dr.Soman K.P","affiliations":[{"name":"CEN"}],"bio":"Use `IEEEbiographynophoto` and the author name\nas the argument followed by the biography text.\n","note":"Template created June 23, 2023; revised `r format(Sys.Date(),format='%B %d, %Y')`."}],"abstract":"This study investigates the application of Singular Value Decomposition (SVD) as an effective mathematical framework for various image processing tasks. SVD offers a unique decomposition approach, making it suitable for applications like image compression, denoising, and watermarking by enabling optimal rank approximations and noise separation. The robustness of SVD in handling large matrices allows it to capture key image characteristics, preserving essential features while reducing data requirements. By leveraging SVD’s ability to separate data into dominant and subdominant subspaces, this research demonstrates enhanced image compression, effective noise reduction, and secure watermark embedding. Experimental results validate SVD's utility in optimizing image storage, clarity, and fidelity, with potential implications for advancing adaptive image processing techniques.\n","keywords":["Singular Value Decomposition (SVD)","Image Processing","Image Compression","Image Denoising","Digital Watermarking","Noise Filtering","Matrix Factorization","Rank Approximation","Frobenius Norm","Energy Compaction","Digital Forensics","Signal Processing","Adaptive Image Processing","Orthogonal Subspaces"],"funding":{"statement":"The `quarto-ieee` template is freely available under the MIT license on github: <https://github.com/dfolio/quarto-ieee>."},"pageheader":{"left":"ASAI, October 2024","right":"Project Report"},"bibliography":"./references.bib","date":"2024-10-30","pdf":"https://github.com/dfolio/quarto-ieee/blob/main/template.pdf","citation":{"container-title":"GitHUB","page":"1-3","type":"software","issued":"2023-06-23","url":"https://github.com/dfolio/quarto-ieee","pdf-url":"https://github.com/dfolio/quarto-ieee/template.pdf"},"execute":{"echo":false},"jupyter":"python3"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\n\nImage processing has become integral to numerous fields, from medical imaging to digital forensics, where large volumes of visual data demand efficient storage, transmission, and quality retention techniques. Among the many mathematical transformations applied to images, Singular Value Decomposition (SVD) has emerged as a particularly valuable tool. SVD is a matrix factorization technique that represents a given matrix as a product of three matrices: $U$, $\\Sigma$, and $V^T$. This decomposition is significant in image processing because it maximizes the energy contained in the largest singular values, enabling the creation of compact, high-quality approximations of the original data. Unlike other transformations, SVD does not require a specific image size or type, making it highly adaptable and robust for various image processing tasks.\n\nThe primary strength of SVD lies in its capacity to separate image data into meaningful components. For instance, in an image represented by SVD, the larger singular values and their corresponding vectors encode most of the structural content, while smaller singular values can often represent noise. This property is beneficial for applications requiring data reduction, such as image compression and denoising, where maintaining the primary structure while reducing extraneous information is essential. Additionally, SVD’s stable mathematical foundation and adaptability have made it increasingly popular in other specialized applications, including watermarking for digital forensics and security.\n\nIn image compression, SVD enables reduced data storage by approximating the image using fewer singular values, providing a balance between quality and compression ratio. This application is critical in fields where storage and bandwidth are constrained. Similarly, in denoising, SVD can isolate noise by exploiting the decomposition’s ability to differentiate between dominant and subdominant subspaces, allowing effective noise suppression without significantly affecting the image’s core structure. Furthermore, SVD is also used in watermarking, where slight modifications to specific singular values embed unique patterns within images, enhancing security and ensuring authenticity.\n\nDespite these advantages, SVD in image processing remains an area with unexplored potential. This paper explores these established applications while addressing underutilized SVD properties to uncover new applications. By investigating SVD's adaptive properties in compressing and filtering images, as well as its potential for encoding data securely, this work contributes to a growing body of research on SVD-based image processing and presents promising directions for further study.\n\n# SVD Application in Image Processing\n\nSingular Value Decomposition (SVD) has several important applications in image processing. The SVD can be used to reduce the noise or compress matrix data by eliminating small singular values or higher ranks @Chen2018SingularVD. This allows for the size of stored images to be reduced @cao2006singular. Additionally, the SVD has properties that make it useful for various image processing tasks, such as enhancing image quality and filtering out noise. The main theorem of SVD is reviewed in the search results, and numerical experiments have been conducted to illustrate its applications in image processing.\n\n## Image Compression\n\nImage compression represents a vital technique to reduce the data needed to represent an image. This is crucial for achieving efficient storage and transmission across various applications, including digital photography, video streaming, and web graphics. Compression methods are primarily categorized into two distinct types: lossy and lossless.\n\nLossy compression diminishes file size by irreversibly eliminating certain image data, which can result in a degradation of image quality, as observed in JPEG formats. This method is frequently employed when the reduction of file size is of paramount importance, and any resultant loss in quality is considered acceptable.\n\nConversely, lossless compression techniques allow for the compression of images without any loss of data, facilitating the exact reconstruction of the original image, as exemplified by PNG formats. This approach is beneficial when preserving image quality is essential and minimizing file size is of lesser importance.\n\nThe decision to use either lossy or lossless compression hinges on the specific needs of the application, balancing the trade-offs between file size and image quality.\n\nSVD-based image compression functions by decomposing the image matrix into three components and subsequently approximating the original matrix with only the most significant singular values and vectors. This process results in a compact image representation while preserving the essential information.\n\nMathematically, given an image represented as a matrix $A$ with dimensions $m \\times n$, the Singular Value Decomposition (SVD) decomposes $A$ into three matrices: $U$, $\\Sigma$, and $V^T$. Here, $U$ is an $m \\times m$ orthogonal matrix containing the left singular vectors, $\\Sigma$ is an $m \\times n$ diagonal matrix containing singular values, and $V^T$ is the transpose of an $n \\times n$ orthogonal matrix containing the right singular vectors. To compress the image, we keep only the top $k$ singular values (where $k$ is significantly smaller than both $m$ and $n$). The compressed image can be reconstructed as \n\n$$\nA_k = U_k \\Sigma_k V_k^T,\n$$\n\nwhere $U_k$ contains the first $k$ columns of $U$, $\\Sigma_k$ is a $k \\times k$ diagonal matrix of the top $k$ singular values, and $V_k^T$ consists of the first $k$ rows of $V^T$.\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Read and convert the image to grayscale\nimg = Image.open('amrita_campus.jpg')  # Specify your image file\ngray_img = img.convert('L')  # Convert to grayscale\nA = np.array(gray_img, dtype=np.float64)  # Convert to float64 for SVD computation\noriginal=A\n# Apply Singular Value Decomposition (SVD)\nU, S, Vt = np.linalg.svd(A, full_matrices=False)\n\n# Choose the number of singular values to keep for compression\nk = 50  # You can adjust this value to see different compression levels\n\n# Create a compressed version of the image using the first k singular values\nS_k = np.zeros_like(A)  # Initialize a zero matrix for S_k\nS_k[:k, :k] = np.diag(S[:k])  # Keep only the top k singular values\n\n# Reconstruct the compressed image\nA_k = np.dot(U[:, :k], np.dot(S_k[:k, :k], Vt[:k, :]))  # Reconstruct the image from the reduced SVD\n\n# Display the original and compressed images\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.imshow(A, cmap='gray', vmin=0, vmax=255)  # Display original image\nplt.title('Original Image')\nplt.axis('off')\n\nplt.subplot(1, 2, 2)\nplt.imshow(A_k, cmap='gray', vmin=0, vmax=255)  # Display compressed image\nplt.title(f'Compressed Image (k = {k})')\nplt.axis('off')\n\nplt.show()\n```\n\nTo assess the quality of the original and compressed images, various metrics can be employed. Commonly used measures are discussion in this section.\n\n### Image Quality Assessment Metrics\n\nTo evaluate the quality of compressed images relative to their original versions, several standardized metrics are commonly employed. These metrics provide quantitative comparisons across aspects such as pixel-level error, signal fidelity, structural similarity, and compression efficiency. The following are the key metrics used in image quality assessment:\n\n####  Mean Squared Error (MSE)\nThe Mean Squared Error quantifies the average squared difference between corresponding pixel values of the original and compressed images. Lower values indicate higher fidelity to the original. Mathematically, MSE is defined as:\n$$\n\\text{MSE} = \\frac{1}{m \\cdot n} \\sum_{i=1}^{m} \\sum_{j=1}^{n} (A(i,j) - A_k(i,j))^2\n$$\nwhere $A(i,j)$ and $A_k(i,j)$ denote the pixel values of the original and compressed images, respectively, and $m \\times n$ represents the image dimensions.\n\n#### Peak Signal-to-Noise Ratio (PSNR)\nPSNR is a widely used metric that compares the maximum possible signal value to the noise level introduced by compression. It is computed as:\n$$\n\\text{PSNR} = 10 \\cdot \\log_{10} \\left( \\frac{\\text{MAX}^2}{\\text{MSE}} \\right)\n$$\nwhere $\\text{MAX}$ represents the maximum pixel value (e.g., 255 for 8-bit images). Higher PSNR values indicate better image quality, as they correspond to lower MSE values.\n\n#### Structural Similarity Index (SSIM)\nThe Structural Similarity Index assesses perceptual similarity by analyzing luminance, contrast, and structural information between the original and compressed images. The SSIM index, ranging from -1 to 1, is calculated as:\n$$\n\\text{SSIM}(A, A_k) = \\frac{(2 \\mu_A \\mu_{A_k} + C_1)(2 \\sigma_{AA_k} + C_2)}{(\\mu_A^2 + \\mu_{A_k}^2 + C_1)(\\sigma_A^2 + \\sigma_{A_k}^2 + C_2)}\n$$\nwhere $\\mu$, $\\sigma$, and $\\sigma_{AA_k}$ denote means, variances, and covariances of $A$ and $A_k$, with constants $C_1$ and $C_2$ to prevent division by zero. Higher SSIM values suggest higher structural fidelity.\n\n#### Compression Ratio (CR)\nCompression Ratio quantifies the efficiency of compression, calculated as the ratio of the original image size to the compressed size:\n$$\n\\text{Compression Ratio} = \\frac{\\text{Size of Original Image}}{\\text{Size of Compressed Image}}\n$$\nA higher compression ratio indicates a greater reduction in file size, which is desirable in applications requiring efficient storage or transmission.\n\n#### Normalized Cross-Correlation (NCC)\nNormalized Cross-Correlation measures the similarity in pixel intensity patterns between the original and compressed images. NCC is calculated as:\n$$\n\\text{NCC} = \\frac{\\sum (A \\cdot A_k)}{\\sqrt{\\sum A^2 \\cdot \\sum A_k^2}}\n$$\nValues closer to 1 indicate a stronger correlation, signifying greater retention of the original image characteristics in the compressed version.\n\nThese metrics collectively provide a comprehensive assessment of image quality by addressing both objective and perceptual aspects of compression, making them suitable for a wide range of applications in image processing and computer vision.\n\n\n\n:::{#tbl-quality-metrics}\n| Metric                               | Value          |\n|:-------------------------------------|----------------|\n| Mean Squared Error (MSE)             | 110.2853       |\n| Peak Signal-to-Noise Ratio (PSNR)    | 27.7056 dB     |\n| Structural Similarity Index (SSIM)   | 0.8116         |\n| Compression Ratio (CR)               | 10.78          |\n| Normalized Cross-Correlation (NCC)   | 0.9976         |\n| Original Image Size                  | 9709.38 KB     |\n| Compressed Image Size                | 900.78 KB      |\n| Size Reduction                       | 8808.59 KB     |\n\n: Quality assessment metrics for original and compressed images, detailing standard measures of image compression and fidelity.\n:::\n\nThe quality assessment metrics indicate effective compression with minimal loss of fidelity in the image. A Mean Squared Error (MSE) of 110.29 suggests that the average pixel intensity differences between the original and compressed images are small. The Peak Signal-to-Noise Ratio (PSNR) of 27.71 dB, typically above the 30 dB threshold for high-quality compression, indicates moderate quality but acceptable for many applications.\n\nThe Structural Similarity Index (SSIM) of 0.8116, close to 1, suggests that the perceptual similarity between the images remains high. The Compression Ratio (CR) of 10.78 shows significant size reduction, and the Normalized Cross-Correlation (NCC) of 0.9976 demonstrates a high correlation between the original and compressed images, supporting strong structural consistency.\n\nThe compressed image achieves substantial size reduction (from 9709.38 KB to 900.78 KB) with reasonable preservation of visual quality, making it suitable for applications prioritizing storage efficiency without heavily compromising visual fidelity.\n\nThe table below presents a comparison of compression quality metrics for three different image compression methods: Singular Value Decomposition (SVD), Discrete Cosine Transform (DCT), and Wavelet Transform. The metrics included are Mean Squared Error (MSE), Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), Compression Ratio (CR), Normalized Cross-Correlation (NCC), Compressed Size, and Size Reduction. Each metric provides insight into the effectiveness of the compression techniques in terms of image quality and storage efficiency.\n\n:::{#tbl-quality-assessment}\n| Method   |      MSE      |     PSNR (dB)     |      SSIM      |    CR    |     NCC     | Compressed Size (KB) |\n|----------|---------------|-------------------|----------------|----------|-------------|----------------------|\n| SVD      | 282.9933     | 23.6130           | 0.7122         | 6.88     | 0.9938      | 176.33               |\n| DCT      | 1172.0801    | 17.4412           | 0.5914         | 2.28     | 0.9741      | 531.82               |\n| Wavelet  | 0.0197       | 65.1859           | 0.9999         | 0.12     | 1.0000      | 9715.31              |\n: Quality assessment metrics for original and compressed images in comparison with popular image compression algorithms.\n:::\n\nThe results demonstrate that Singular Value Decomposition (SVD) offers a superior balance between image quality and compression efficiency compared to Discrete Cosine Transform (DCT) and Wavelet Transform. With a significantly lower Mean Squared Error (MSE) and a Peak Signal-to-Noise Ratio (PSNR) of 23.6130 dB, SVD preserves the original image quality more effectively than DCT (17.4412 dB) and offers practical structural similarity (SSIM) of 0.7122. In contrast, while the Wavelet method achieves excellent PSNR (65.1859 dB) and SSIM (0.9999), its large compressed size (9715.31 KB) renders it impractical for many applications.\n\nIn terms of compression efficiency, SVD yields a Compression Ratio (CR) of 6.88 with a manageable compressed size of 176.33 KB, resulting in a significant size reduction of 1037.34 KB. This contrasts sharply with DCT’s lower CR of 2.28 and Wavelet’s CR of 0.12, which implies an increase in size for the latter. Overall, SVD stands out as a robust image compression method, effectively maintaining quality while achieving substantial reductions in storage requirements, making it particularly advantageous for applications prioritizing both quality and efficiency.\n\n## SVD Architecture and Denoising\n\nThe Singular Value Decomposition (SVD) architecture provides a powerful framework for analyzing and compressing images. In the context of image decomposition, the singular values (SVs) represent the luminance levels of various layers within the image, while the corresponding singular vectors (SCs) define the geometric characteristics of these layers. \n\nWhen applied to a high-resolution image, SVD enables the extraction of significant image content through the left singular matrix, capturing the primary structures and features. Conversely, the right singular matrix isolates the noise components, which are typically linked to the smaller singular values found in the diagonal matrix, $\\Sigma$. \n\nThus, the largest singular values correspond to the most prominent image features, often referred to as eigenimages, while the noise components are associated with the smaller singular values. This decomposition allows for a clear distinction between meaningful image information and noise, facilitating effective compression and analysis. By leveraging SVD, one can efficiently manage and manipulate image data, ensuring that essential visual content is retained while minimizing the impact of noise.\n\n\n","srcMarkdownNoYaml":"\n\n\n# Introduction\n\nImage processing has become integral to numerous fields, from medical imaging to digital forensics, where large volumes of visual data demand efficient storage, transmission, and quality retention techniques. Among the many mathematical transformations applied to images, Singular Value Decomposition (SVD) has emerged as a particularly valuable tool. SVD is a matrix factorization technique that represents a given matrix as a product of three matrices: $U$, $\\Sigma$, and $V^T$. This decomposition is significant in image processing because it maximizes the energy contained in the largest singular values, enabling the creation of compact, high-quality approximations of the original data. Unlike other transformations, SVD does not require a specific image size or type, making it highly adaptable and robust for various image processing tasks.\n\nThe primary strength of SVD lies in its capacity to separate image data into meaningful components. For instance, in an image represented by SVD, the larger singular values and their corresponding vectors encode most of the structural content, while smaller singular values can often represent noise. This property is beneficial for applications requiring data reduction, such as image compression and denoising, where maintaining the primary structure while reducing extraneous information is essential. Additionally, SVD’s stable mathematical foundation and adaptability have made it increasingly popular in other specialized applications, including watermarking for digital forensics and security.\n\nIn image compression, SVD enables reduced data storage by approximating the image using fewer singular values, providing a balance between quality and compression ratio. This application is critical in fields where storage and bandwidth are constrained. Similarly, in denoising, SVD can isolate noise by exploiting the decomposition’s ability to differentiate between dominant and subdominant subspaces, allowing effective noise suppression without significantly affecting the image’s core structure. Furthermore, SVD is also used in watermarking, where slight modifications to specific singular values embed unique patterns within images, enhancing security and ensuring authenticity.\n\nDespite these advantages, SVD in image processing remains an area with unexplored potential. This paper explores these established applications while addressing underutilized SVD properties to uncover new applications. By investigating SVD's adaptive properties in compressing and filtering images, as well as its potential for encoding data securely, this work contributes to a growing body of research on SVD-based image processing and presents promising directions for further study.\n\n# SVD Application in Image Processing\n\nSingular Value Decomposition (SVD) has several important applications in image processing. The SVD can be used to reduce the noise or compress matrix data by eliminating small singular values or higher ranks @Chen2018SingularVD. This allows for the size of stored images to be reduced @cao2006singular. Additionally, the SVD has properties that make it useful for various image processing tasks, such as enhancing image quality and filtering out noise. The main theorem of SVD is reviewed in the search results, and numerical experiments have been conducted to illustrate its applications in image processing.\n\n## Image Compression\n\nImage compression represents a vital technique to reduce the data needed to represent an image. This is crucial for achieving efficient storage and transmission across various applications, including digital photography, video streaming, and web graphics. Compression methods are primarily categorized into two distinct types: lossy and lossless.\n\nLossy compression diminishes file size by irreversibly eliminating certain image data, which can result in a degradation of image quality, as observed in JPEG formats. This method is frequently employed when the reduction of file size is of paramount importance, and any resultant loss in quality is considered acceptable.\n\nConversely, lossless compression techniques allow for the compression of images without any loss of data, facilitating the exact reconstruction of the original image, as exemplified by PNG formats. This approach is beneficial when preserving image quality is essential and minimizing file size is of lesser importance.\n\nThe decision to use either lossy or lossless compression hinges on the specific needs of the application, balancing the trade-offs between file size and image quality.\n\nSVD-based image compression functions by decomposing the image matrix into three components and subsequently approximating the original matrix with only the most significant singular values and vectors. This process results in a compact image representation while preserving the essential information.\n\nMathematically, given an image represented as a matrix $A$ with dimensions $m \\times n$, the Singular Value Decomposition (SVD) decomposes $A$ into three matrices: $U$, $\\Sigma$, and $V^T$. Here, $U$ is an $m \\times m$ orthogonal matrix containing the left singular vectors, $\\Sigma$ is an $m \\times n$ diagonal matrix containing singular values, and $V^T$ is the transpose of an $n \\times n$ orthogonal matrix containing the right singular vectors. To compress the image, we keep only the top $k$ singular values (where $k$ is significantly smaller than both $m$ and $n$). The compressed image can be reconstructed as \n\n$$\nA_k = U_k \\Sigma_k V_k^T,\n$$\n\nwhere $U_k$ contains the first $k$ columns of $U$, $\\Sigma_k$ is a $k \\times k$ diagonal matrix of the top $k$ singular values, and $V_k^T$ consists of the first $k$ rows of $V^T$.\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Read and convert the image to grayscale\nimg = Image.open('amrita_campus.jpg')  # Specify your image file\ngray_img = img.convert('L')  # Convert to grayscale\nA = np.array(gray_img, dtype=np.float64)  # Convert to float64 for SVD computation\noriginal=A\n# Apply Singular Value Decomposition (SVD)\nU, S, Vt = np.linalg.svd(A, full_matrices=False)\n\n# Choose the number of singular values to keep for compression\nk = 50  # You can adjust this value to see different compression levels\n\n# Create a compressed version of the image using the first k singular values\nS_k = np.zeros_like(A)  # Initialize a zero matrix for S_k\nS_k[:k, :k] = np.diag(S[:k])  # Keep only the top k singular values\n\n# Reconstruct the compressed image\nA_k = np.dot(U[:, :k], np.dot(S_k[:k, :k], Vt[:k, :]))  # Reconstruct the image from the reduced SVD\n\n# Display the original and compressed images\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.imshow(A, cmap='gray', vmin=0, vmax=255)  # Display original image\nplt.title('Original Image')\nplt.axis('off')\n\nplt.subplot(1, 2, 2)\nplt.imshow(A_k, cmap='gray', vmin=0, vmax=255)  # Display compressed image\nplt.title(f'Compressed Image (k = {k})')\nplt.axis('off')\n\nplt.show()\n```\n\nTo assess the quality of the original and compressed images, various metrics can be employed. Commonly used measures are discussion in this section.\n\n### Image Quality Assessment Metrics\n\nTo evaluate the quality of compressed images relative to their original versions, several standardized metrics are commonly employed. These metrics provide quantitative comparisons across aspects such as pixel-level error, signal fidelity, structural similarity, and compression efficiency. The following are the key metrics used in image quality assessment:\n\n####  Mean Squared Error (MSE)\nThe Mean Squared Error quantifies the average squared difference between corresponding pixel values of the original and compressed images. Lower values indicate higher fidelity to the original. Mathematically, MSE is defined as:\n$$\n\\text{MSE} = \\frac{1}{m \\cdot n} \\sum_{i=1}^{m} \\sum_{j=1}^{n} (A(i,j) - A_k(i,j))^2\n$$\nwhere $A(i,j)$ and $A_k(i,j)$ denote the pixel values of the original and compressed images, respectively, and $m \\times n$ represents the image dimensions.\n\n#### Peak Signal-to-Noise Ratio (PSNR)\nPSNR is a widely used metric that compares the maximum possible signal value to the noise level introduced by compression. It is computed as:\n$$\n\\text{PSNR} = 10 \\cdot \\log_{10} \\left( \\frac{\\text{MAX}^2}{\\text{MSE}} \\right)\n$$\nwhere $\\text{MAX}$ represents the maximum pixel value (e.g., 255 for 8-bit images). Higher PSNR values indicate better image quality, as they correspond to lower MSE values.\n\n#### Structural Similarity Index (SSIM)\nThe Structural Similarity Index assesses perceptual similarity by analyzing luminance, contrast, and structural information between the original and compressed images. The SSIM index, ranging from -1 to 1, is calculated as:\n$$\n\\text{SSIM}(A, A_k) = \\frac{(2 \\mu_A \\mu_{A_k} + C_1)(2 \\sigma_{AA_k} + C_2)}{(\\mu_A^2 + \\mu_{A_k}^2 + C_1)(\\sigma_A^2 + \\sigma_{A_k}^2 + C_2)}\n$$\nwhere $\\mu$, $\\sigma$, and $\\sigma_{AA_k}$ denote means, variances, and covariances of $A$ and $A_k$, with constants $C_1$ and $C_2$ to prevent division by zero. Higher SSIM values suggest higher structural fidelity.\n\n#### Compression Ratio (CR)\nCompression Ratio quantifies the efficiency of compression, calculated as the ratio of the original image size to the compressed size:\n$$\n\\text{Compression Ratio} = \\frac{\\text{Size of Original Image}}{\\text{Size of Compressed Image}}\n$$\nA higher compression ratio indicates a greater reduction in file size, which is desirable in applications requiring efficient storage or transmission.\n\n#### Normalized Cross-Correlation (NCC)\nNormalized Cross-Correlation measures the similarity in pixel intensity patterns between the original and compressed images. NCC is calculated as:\n$$\n\\text{NCC} = \\frac{\\sum (A \\cdot A_k)}{\\sqrt{\\sum A^2 \\cdot \\sum A_k^2}}\n$$\nValues closer to 1 indicate a stronger correlation, signifying greater retention of the original image characteristics in the compressed version.\n\nThese metrics collectively provide a comprehensive assessment of image quality by addressing both objective and perceptual aspects of compression, making them suitable for a wide range of applications in image processing and computer vision.\n\n\n\n:::{#tbl-quality-metrics}\n| Metric                               | Value          |\n|:-------------------------------------|----------------|\n| Mean Squared Error (MSE)             | 110.2853       |\n| Peak Signal-to-Noise Ratio (PSNR)    | 27.7056 dB     |\n| Structural Similarity Index (SSIM)   | 0.8116         |\n| Compression Ratio (CR)               | 10.78          |\n| Normalized Cross-Correlation (NCC)   | 0.9976         |\n| Original Image Size                  | 9709.38 KB     |\n| Compressed Image Size                | 900.78 KB      |\n| Size Reduction                       | 8808.59 KB     |\n\n: Quality assessment metrics for original and compressed images, detailing standard measures of image compression and fidelity.\n:::\n\nThe quality assessment metrics indicate effective compression with minimal loss of fidelity in the image. A Mean Squared Error (MSE) of 110.29 suggests that the average pixel intensity differences between the original and compressed images are small. The Peak Signal-to-Noise Ratio (PSNR) of 27.71 dB, typically above the 30 dB threshold for high-quality compression, indicates moderate quality but acceptable for many applications.\n\nThe Structural Similarity Index (SSIM) of 0.8116, close to 1, suggests that the perceptual similarity between the images remains high. The Compression Ratio (CR) of 10.78 shows significant size reduction, and the Normalized Cross-Correlation (NCC) of 0.9976 demonstrates a high correlation between the original and compressed images, supporting strong structural consistency.\n\nThe compressed image achieves substantial size reduction (from 9709.38 KB to 900.78 KB) with reasonable preservation of visual quality, making it suitable for applications prioritizing storage efficiency without heavily compromising visual fidelity.\n\nThe table below presents a comparison of compression quality metrics for three different image compression methods: Singular Value Decomposition (SVD), Discrete Cosine Transform (DCT), and Wavelet Transform. The metrics included are Mean Squared Error (MSE), Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), Compression Ratio (CR), Normalized Cross-Correlation (NCC), Compressed Size, and Size Reduction. Each metric provides insight into the effectiveness of the compression techniques in terms of image quality and storage efficiency.\n\n:::{#tbl-quality-assessment}\n| Method   |      MSE      |     PSNR (dB)     |      SSIM      |    CR    |     NCC     | Compressed Size (KB) |\n|----------|---------------|-------------------|----------------|----------|-------------|----------------------|\n| SVD      | 282.9933     | 23.6130           | 0.7122         | 6.88     | 0.9938      | 176.33               |\n| DCT      | 1172.0801    | 17.4412           | 0.5914         | 2.28     | 0.9741      | 531.82               |\n| Wavelet  | 0.0197       | 65.1859           | 0.9999         | 0.12     | 1.0000      | 9715.31              |\n: Quality assessment metrics for original and compressed images in comparison with popular image compression algorithms.\n:::\n\nThe results demonstrate that Singular Value Decomposition (SVD) offers a superior balance between image quality and compression efficiency compared to Discrete Cosine Transform (DCT) and Wavelet Transform. With a significantly lower Mean Squared Error (MSE) and a Peak Signal-to-Noise Ratio (PSNR) of 23.6130 dB, SVD preserves the original image quality more effectively than DCT (17.4412 dB) and offers practical structural similarity (SSIM) of 0.7122. In contrast, while the Wavelet method achieves excellent PSNR (65.1859 dB) and SSIM (0.9999), its large compressed size (9715.31 KB) renders it impractical for many applications.\n\nIn terms of compression efficiency, SVD yields a Compression Ratio (CR) of 6.88 with a manageable compressed size of 176.33 KB, resulting in a significant size reduction of 1037.34 KB. This contrasts sharply with DCT’s lower CR of 2.28 and Wavelet’s CR of 0.12, which implies an increase in size for the latter. Overall, SVD stands out as a robust image compression method, effectively maintaining quality while achieving substantial reductions in storage requirements, making it particularly advantageous for applications prioritizing both quality and efficiency.\n\n## SVD Architecture and Denoising\n\nThe Singular Value Decomposition (SVD) architecture provides a powerful framework for analyzing and compressing images. In the context of image decomposition, the singular values (SVs) represent the luminance levels of various layers within the image, while the corresponding singular vectors (SCs) define the geometric characteristics of these layers. \n\nWhen applied to a high-resolution image, SVD enables the extraction of significant image content through the left singular matrix, capturing the primary structures and features. Conversely, the right singular matrix isolates the noise components, which are typically linked to the smaller singular values found in the diagonal matrix, $\\Sigma$. \n\nThus, the largest singular values correspond to the most prominent image features, often referred to as eigenimages, while the noise components are associated with the smaller singular values. This decomposition allows for a clear distinction between meaningful image information and noise, facilitating effective compression and analysis. By leveraging SVD, one can efficiently manage and manipulate image data, ensuring that essential visual content is retained while minimizing the impact of noise.\n\n\n"},"formats":{"ieee-html":{"identifier":{"display-name":"HTML","target-format":"ieee-html","base-format":"html","extension-name":"ieee"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"shortcodes":["D:\\SVD_project\\_extensions\\dfolio\\ieee\\_extensions\\quarto-ext\\fancy-text\\fancy-text.lua"]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","number-sections":true,"filters":["D:\\SVD_project\\_extensions\\dfolio\\ieee\\_extensions\\quarto-ext\\latex-environment\\latex-environment.lua","D:\\SVD_project\\_extensions\\dfolio\\ieee\\ieee.lua"],"cite-method":"citeproc","toc":true,"template":"_extensions/dfolio/ieee/partials/ieee-template.html","include-in-header":["_extensions/dfolio/ieee/partials/mathjax.html"],"html-math-method":{"method":"mathjax"},"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.56","environments":["IEEEbiography","IEEEbiographynophoto"],"commands":["IEEEPARstart","appendix"],"crossref":{"chapters":false,"eq-prefix":null,"eq-labels":"(roman)","fig-title":"Fig.","fig-prefix":"Fig."},"csl":"_extensions/dfolio/ieee/ieee-with-url.csl","link-citations":true,"toc-location":"left","toc-title":"Document Sections","theme":["_extensions/dfolio/ieee/styles.scss"],"template-partials":["_extensions/dfolio/ieee/partials/title-block.html","_extensions/dfolio/ieee/partials/title-metadata.html","_extensions/dfolio/ieee/partials/author.html","_extensions/dfolio/ieee/partials/after-body.html","_extensions/dfolio/ieee/partials/affiliation.tex"],"date-format":"D MMMM YYYY","google-scholar":true,"refs":"::: {#refs}\n:::\n","revealjs-plugins":[],"manuscript":{"notebooks":[{"notebook":"Notebooks/introduction","title":"Introduction"}]},"formats":{"ieee-pdf":"default","ieee-html":"default"},"title":"SVD Based Image Processing Applications","author":[{"id":"dfolio","name":"Siju K S","affiliations":[{"name":"Amrita Vishwa Vidyapeetham","department":"School of Artificial Intelligence","city":"Coimbatore","country":"India","postal-code":18800},{"name":"Unknown affiliation"}],"orcid":"0009-0004-1983-5574","email":"siju.swamy@saintgits.org","url":"https://dfolio.fr/","membership":"Member, IEEE","attributes":{"corresponding":true},"photo":"david-folio.png","bio":"Use `IEEEbiography`  with figure as  option and\nthe author name as the argument followed by the biography text.\n"},{"name":"Dr.Soman K.P","affiliations":[{"name":"CEN"}],"bio":"Use `IEEEbiographynophoto` and the author name\nas the argument followed by the biography text.\n","note":"Template created June 23, 2023; revised `r format(Sys.Date(),format='%B %d, %Y')`."}],"abstract":"This study investigates the application of Singular Value Decomposition (SVD) as an effective mathematical framework for various image processing tasks. SVD offers a unique decomposition approach, making it suitable for applications like image compression, denoising, and watermarking by enabling optimal rank approximations and noise separation. The robustness of SVD in handling large matrices allows it to capture key image characteristics, preserving essential features while reducing data requirements. By leveraging SVD’s ability to separate data into dominant and subdominant subspaces, this research demonstrates enhanced image compression, effective noise reduction, and secure watermark embedding. Experimental results validate SVD's utility in optimizing image storage, clarity, and fidelity, with potential implications for advancing adaptive image processing techniques.\n","keywords":["Singular Value Decomposition (SVD)","Image Processing","Image Compression","Image Denoising","Digital Watermarking","Noise Filtering","Matrix Factorization","Rank Approximation","Frobenius Norm","Energy Compaction","Digital Forensics","Signal Processing","Adaptive Image Processing","Orthogonal Subspaces"],"funding":{"statement":"The `quarto-ieee` template is freely available under the MIT license on github: <https://github.com/dfolio/quarto-ieee>."},"pageheader":{"left":"ASAI, October 2024","right":"Project Report"},"bibliography":["./references.bib"],"date":"2024-10-30","pdf":"https://github.com/dfolio/quarto-ieee/blob/main/template.pdf","citation":{"container-title":"GitHUB","page":"1-3","type":"software","issued":"2023-06-23","url":"https://github.com/dfolio/quarto-ieee","pdf-url":"https://github.com/dfolio/quarto-ieee/template.pdf"},"jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":[]}