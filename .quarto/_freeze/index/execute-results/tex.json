{
  "hash": "55076f5f882cc0a78e93f53f86592e7a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: SVD Based Image Processing Applications\nformat:\n  ieee-pdf:\n    keep-tex: true  \n  ieee-html: default\nauthor:\n  - id: dfolio\n    name: Siju K S\n    affiliations:\n      - name: Amrita Vishwa Vidyapeetham\n        department: School of Artificial Intelligence\n        city: Coimbatore\n        country: India\n        postal-code: 18800\n      - name: Unknown affiliation\n    orcid: 0009-0004-1983-5574\n    email: siju.swamy@saintgits.org\n    url: https://dfolio.fr/\n    membership: \"Member, IEEE\"\n    attributes:\n      corresponding: true\n    photo: david-folio.png\n    bio: |\n      Use `IEEEbiography`  with figure as  option and\n      the author name as the argument followed by the biography text.\n  - name: John Doe\n    affiliations: \n      - name: Anonymous University\n    bio: |\n      Use `IEEEbiographynophoto` and the author name\n      as the argument followed by the biography text.\n    note: \"Template created June 23, 2023; revised `r format(Sys.Date(),format='%B %d, %Y')`.\"\nabstract: |\n  This study investigates the application of Singular Value Decomposition (SVD) as an effective mathematical framework for various image processing tasks. SVD offers a unique decomposition approach, making it suitable for applications like image compression, denoising, and watermarking by enabling optimal rank approximations and noise separation. The robustness of SVD in handling large matrices allows it to capture key image characteristics, preserving essential features while reducing data requirements. By leveraging SVD’s ability to separate data into dominant and subdominant subspaces, this research demonstrates enhanced image compression, effective noise reduction, and secure watermark embedding. Experimental results validate SVD's utility in optimizing image storage, clarity, and fidelity, with potential implications for advancing adaptive image processing techniques.\nkeywords: [Singular Value Decomposition (SVD), Image Processing, Image Compression, Image Denoising, Digital Watermarking, Noise Filtering, Matrix Factorization, Rank Approximation, Frobenius Norm, Energy Compaction, Digital Forensics, Signal Processing, Adaptive Image Processing, Orthogonal Subspaces]\n#funding: \nfunding: \n  statement: \"The `quarto-ieee` template is freely available under the MIT license on github: <https://github.com/dfolio/quarto-ieee>.\"\npageheader:\n  left: ASAI, October 2024\n  right: 'Project Report'\nbibliography: ./references.bib\ndate: 2024-10-30\npdf: https://github.com/dfolio/quarto-ieee/blob/main/template.pdf\ncitation: \n  container-title: GitHUB\n  page: 1-3\n  type: software\n  issued: 2023-06-23\n  url: https://github.com/dfolio/quarto-ieee\n  pdf-url: https://github.com/dfolio/quarto-ieee/template.pdf\n\njupyter: python3\n---\n\n\n\n# Introduction\n\nImage processing has become integral to numerous fields, from medical imaging to digital forensics, where large volumes of visual data demand efficient storage, transmission, and quality retention techniques. Among the many mathematical transformations applied to images, Singular Value Decomposition (SVD) has emerged as a particularly valuable tool. SVD is a matrix factorization technique that represents a given matrix as a product of three matrices: $U$, $\\Sigma$, and $V^T$. This decomposition is significant in image processing because it maximizes the energy contained in the largest singular values, enabling the creation of compact, high-quality approximations of the original data. Unlike other transformations, SVD does not require a specific image size or type, making it highly adaptable and robust for various image processing tasks.\n\nThe primary strength of SVD lies in its capacity to separate image data into meaningful components. For instance, in an image represented by SVD, the larger singular values and their corresponding vectors encode most of the structural content, while smaller singular values can often represent noise. This property is beneficial for applications requiring data reduction, such as image compression and denoising, where maintaining the primary structure while reducing extraneous information is essential. Additionally, SVD’s stable mathematical foundation and adaptability have made it increasingly popular in other specialized applications, including watermarking for digital forensics and security.\n\nIn image compression, SVD enables reduced data storage by approximating the image using fewer singular values, providing a balance between quality and compression ratio. This application is critical in fields where storage and bandwidth are constrained. Similarly, in denoising, SVD can isolate noise by exploiting the decomposition’s ability to differentiate between dominant and subdominant subspaces, allowing effective noise suppression without significantly affecting the image’s core structure. Furthermore, SVD is also used in watermarking, where slight modifications to specific singular values embed unique patterns within images, enhancing security and ensuring authenticity.\n\nDespite these advantages, SVD in image processing remains an area with unexplored potential. This paper explores these established applications while addressing underutilized SVD properties to uncover new applications. By investigating SVD's adaptive properties in compressing and filtering images, as well as its potential for encoding data securely, this work contributes to a growing body of research on SVD-based image processing and presents promising directions for further study.\n\n# SVD Application in Image Processing\n\nSingular Value Decomposition (SVD) has several important applications in image processing. The SVD can be used to reduce the noise or compress matrix data by eliminating small singular values or higher ranks @Chen2018SingularVD. This allows for the size of stored images to be reduced @cao2006singular. Additionally, the SVD has properties that make it useful for various image processing tasks, such as enhancing image quality and filtering out noise. The main theorem of SVD is reviewed in the search results, and numerical experiments have been conducted to illustrate its applications in image processing.\n\n## Image Compression\n\nImage compression represents a vital technique to reduce the data needed to represent an image. This is crucial for achieving efficient storage and transmission across various applications, including digital photography, video streaming, and web graphics. Compression methods are primarily categorized into two distinct types: lossy and lossless.\n\nLossy compression diminishes file size by irreversibly eliminating certain image data, which can result in a degradation of image quality, as observed in JPEG formats. This method is frequently employed when the reduction of file size is of paramount importance, and any resultant loss in quality is considered acceptable.\n\nConversely, lossless compression techniques allow for the compression of images without any loss of data, facilitating the exact reconstruction of the original image, as exemplified by PNG formats. This approach is beneficial when preserving image quality is essential and minimizing file size is of lesser importance.\n\nThe decision to use either lossy or lossless compression hinges on the specific needs of the application, balancing the trade-offs between file size and image quality.\n\nSVD-based image compression functions by decomposing the image matrix into three components and subsequently approximating the original matrix with only the most significant singular values and vectors. This process results in a compact image representation while preserving the essential information.\n\nMathematically, given an image represented as a matrix $A$ with dimensions $m \\times n$, the Singular Value Decomposition (SVD) decomposes $A$ into three matrices: $U$, $\\Sigma$, and $V^T$. Here, $U$ is an $m \\times m$ orthogonal matrix containing the left singular vectors, $\\Sigma$ is an $m \\times n$ diagonal matrix containing singular values, and $V^T$ is the transpose of an $n \\times n$ orthogonal matrix containing the right singular vectors. To compress the image, we keep only the top $k$ singular values (where $k$ is significantly smaller than both $m$ and $n$). The compressed image can be reconstructed as \n\n$$\nA_k = U_k \\Sigma_k V_k^T,\n$$\n\nwhere $U_k$ contains the first $k$ columns of $U$, $\\Sigma_k$ is a $k \\times k$ diagonal matrix of the top $k$ singular values, and $V_k^T$ consists of the first $k$ rows of $V^T$.\n\n\n:::{.panel-tabset}\n\n## Code\n```{.matlab}\n\n% Read and convert the image to grayscale\nimg = imread('amrita_campus.jpg'); % Specify your image file\ngray_img = rgb2gray(img); % Convert to grayscale\nA = double(gray_img); % Convert to double for SVD computation\n\n% Apply Singular Value Decomposition (SVD)\n[U, S, V] = svd(A)\n\n% Choose the number of singular values to keep for compression\nk = 50; % You can adjust this value to see different compression levels\n\n% Create a compressed version of the image using the first k singular values\nS_k = zeros(size(A)); % Initialize a zero matrix for S_k\nS_k(1:k, 1:k) = S(1:k, 1:k); % Keep only the top k singular values\n\n% Reconstruct the compressed image\nA_k = U*S_k*V'; % Reconstruct the image from the reduced SVD\n\n% Display the original and compressed images\nfigure;\nsubplot(1, 2, 1);\nimshow(uint8(A)); % Display original image\ntitle('Original Image');\n\nsubplot(1, 2, 2);\nimshow(uint8(A_k)); % Display compressed image\ntitle(['Compressed Image (k = ', num2str(k), ')']);\n```\n\n## Output\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-pdf/cell-2-output-1.pdf){}\n:::\n:::\n\n\n:::\n\nTo assess the quality of the original and compressed images, various metrics can be employed. Two common measures are Peak Signal-to-Noise Ratio (PSNR) and Mean Squared Error (MSE).\n\nThe Mean Squared Error quantifies the average squared difference between pixel values of the original and compressed images. It is defined as:\n\n$$\n\\text{MSE} = \\frac{1}{m \\cdot n} \\sum_{i=1}^{m} \\sum_{j=1}^{n} (A(i,j) - A_k(i,j))^2\n$$\n\nwhere $m$ and $n$ are the dimensions of the image, $A(i,j)$ is the pixel value of the original image, and $A_k(i,j)$ is the pixel value of the compressed image.\n\nThe Peak Signal-to-Noise Ratio (PSNR) is a measure that compares the maximum possible power of a signal to the power of corrupting noise that affects the fidelity of its representation. It is given by:\n\n$$\n\\text{PSNR} = 10 \\cdot \\log_{10}\\left(\\frac{M_{\\text{AX}}^2}{\\text{MSE}}\\right)\n$$\n\nwhere $M_{\\text{AX}}$ is the maximum pixel value, typically 255 for an 8-bit image.\n\nBelow is the additional MATLAB code to calculate MSE and PSNR:\n\n:::{.panel-tabset}\n\n### Code\n\n```{.matlab}\n% Calculate Mean Squared Error (MSE)\nmse = mean((A(:) - A_k(:)).^2);\n\n% Calculate Peak Signal-to-Noise Ratio (PSNR)\nmax_pixel_value = 255; % Maximum pixel value for 8-bit images\npsnr = 10 * log10((max_pixel_value^2) / mse);\n\n% Calculate sizes\noriginal_size = numel(A) * 8; % Size of the original image in bytes (double data type)\ncompressed_size = (k * (size(A, 1) + size(A, 2))) * 8; % Size of compressed representation (U, S_k, V)\n\n% Display results\nfprintf('Mean Squared Error (MSE): %.4f\\n', mse);\nfprintf('Peak Signal-to-Noise Ratio (PSNR): %.4f dB\\n', psnr);\nfprintf('Original Image Size: %.2f KB\\n', original_size / 1024); % Convert to KB\nfprintf('Compressed Image Size: %.2f KB\\n', compressed_size / 1024); % Convert to KB\nfprintf('Size Reduction: %.2f KB\\n', (original_size - compressed_size) / 1024); % Convert to KB\n```\n\n### Output\n\n::: {.cell execution_count=2}\n\n::: {.cell-output .cell-output-stdout}\n```\nMean Squared Error (MSE): 110.2853\nPeak Signal-to-Noise Ratio (PSNR): 27.7056 dB\nOriginal Image Size: 9709.38 KB\nCompressed Image Size: 900.78 KB\nSize Reduction: 8808.59 KB\n```\n:::\n:::\n\n\n:::\n\n",
    "supporting": [
      "index_files\\figure-pdf"
    ],
    "filters": []
  }
}